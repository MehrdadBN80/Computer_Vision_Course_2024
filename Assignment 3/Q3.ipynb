{"cells":[{"cell_type":"code","execution_count":63,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-14T11:09:27.405200Z","iopub.status.busy":"2024-06-14T11:09:27.404393Z","iopub.status.idle":"2024-06-14T11:09:27.411098Z","shell.execute_reply":"2024-06-14T11:09:27.409966Z","shell.execute_reply.started":"2024-06-14T11:09:27.405165Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import csv\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data import Dataset\n","\n","from torchvision import transforms\n","\n","from PIL import Image"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T11:09:27.413235Z","iopub.status.busy":"2024-06-14T11:09:27.412920Z","iopub.status.idle":"2024-06-14T11:09:27.427048Z","shell.execute_reply":"2024-06-14T11:09:27.426130Z","shell.execute_reply.started":"2024-06-14T11:09:27.413210Z"},"trusted":true},"outputs":[],"source":["def extract_frames(video_path, output_folder, output_csv):\n","    # Open the video file\n","    cap = cv2.VideoCapture(video_path)\n","    \n","    # Check if the video opened successfully\n","    if not cap.isOpened():\n","        print(\"Error opening video file\")\n","        return\n","    \n","    # Create an output folder if it doesn't exist\n","    import os\n","    os.makedirs(output_folder, exist_ok=True)\n","    \n","    frame_count = 0\n","    frames_info = []\n","    \n","    while True:\n","        # Read a frame from the video file\n","        ret, frame = cap.read()\n","        \n","        if not ret:\n","            break\n","        \n","        frame_count += 1\n","        frame_info = {'Frame': frame_count, 'Dimensions': frame.shape[:2]}\n","        frames_info.append(frame_info)\n","        \n","        # Save frame as image file\n","        frame_filename = f\"{output_folder}/frame_{frame_count:04d}.jpg\"\n","        cv2.imwrite(frame_filename, frame)\n","    \n","    # Release the VideoCapture object and close all windows\n","    cap.release()\n","\n","    # Convert frames_info to DataFrame\n","    df = pd.DataFrame(frames_info)\n","    \n","    # Save DataFrame to CSV file\n","    csv_filename = f\"{output_csv}/frame_info.csv\"\n","    df.to_csv(csv_filename, index=False)\n","    \n","    return frame_count"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T11:09:27.429496Z","iopub.status.busy":"2024-06-14T11:09:27.429163Z","iopub.status.idle":"2024-06-14T11:09:27.438154Z","shell.execute_reply":"2024-06-14T11:09:27.437320Z","shell.execute_reply.started":"2024-06-14T11:09:27.429465Z"},"trusted":true},"outputs":[],"source":["video_path = '/kaggle/input/q3-computer-vision/train.mp4'\n","output_folder = '/kaggle/working/frames_train'\n","output_csv = '/kaggle/working/'"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T11:09:27.439972Z","iopub.status.busy":"2024-06-14T11:09:27.439192Z","iopub.status.idle":"2024-06-14T11:09:28.491117Z","shell.execute_reply":"2024-06-14T11:09:28.488209Z","shell.execute_reply.started":"2024-06-14T11:09:27.439938Z"},"trusted":true},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m total_frames \u001b[38;5;241m=\u001b[39m \u001b[43mextract_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal frames extracted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_frames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[64], line 30\u001b[0m, in \u001b[0;36mextract_frames\u001b[0;34m(video_path, output_folder, output_csv)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Save frame as image file\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     frame_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/frame_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe_count\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Release the VideoCapture object and close all windows\u001b[39;00m\n\u001b[1;32m     33\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["total_frames = extract_frames(video_path, output_folder, output_csv)\n","print(f\"Total frames extracted: {total_frames}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.492298Z","iopub.status.idle":"2024-06-14T11:09:28.492673Z","shell.execute_reply":"2024-06-14T11:09:28.492475Z","shell.execute_reply.started":"2024-06-14T11:09:28.492461Z"},"trusted":true},"outputs":[],"source":["video_path = '/kaggle/input/q3-computer-vision/test.mp4'\n","output_folder = '/kaggle/working/frames_test'\n","output_csv = '/kaggle/working/'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.493797Z","iopub.status.idle":"2024-06-14T11:09:28.494266Z","shell.execute_reply":"2024-06-14T11:09:28.494053Z","shell.execute_reply.started":"2024-06-14T11:09:28.494033Z"},"trusted":true},"outputs":[],"source":["total_frames = extract_frames(video_path, output_folder, output_csv)\n","print(f\"Total frames extracted test: {total_frames}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.495630Z","iopub.status.idle":"2024-06-14T11:09:28.496100Z","shell.execute_reply":"2024-06-14T11:09:28.495878Z","shell.execute_reply.started":"2024-06-14T11:09:28.495856Z"},"trusted":true},"outputs":[],"source":["def convertToOptical(prev_image, curr_image):\n","    prev_image_gray = cv2.cvtColor(prev_image, cv2.COLOR_BGR2GRAY)\n","    curr_image_gray = cv2.cvtColor(curr_image, cv2.COLOR_BGR2GRAY)\n","\n","    flow = cv2.calcOpticalFlowFarneback(prev_image_gray, curr_image_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n","\n","    hsv = np.zeros_like(prev_image)\n","    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n","    hsv[..., 0] = ang * 180 / np.pi / 2\n","    hsv[..., 1] = 255\n","    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n","    flow_image_bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n","\n","    return flow_image_bgr"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.497360Z","iopub.status.idle":"2024-06-14T11:09:28.497866Z","shell.execute_reply":"2024-06-14T11:09:28.497662Z","shell.execute_reply.started":"2024-06-14T11:09:28.497643Z"},"trusted":true},"outputs":[],"source":["def compute_optical_flow(input_folder, output_folder):\n","    # Create output folder if it doesn't exist\n","    os.makedirs(output_folder, exist_ok=True)\n","    \n","    frame_files = sorted([f for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg', '.jpeg'))])\n","    \n","    prev_frame = None\n","    for i, frame_file in enumerate(tqdm(frame_files, desc=\"Processing frames\")):\n","        frame_path = os.path.join(input_folder, frame_file)\n","        curr_frame = cv2.imread(frame_path)\n","        \n","        if prev_frame is not None:\n","            optical_flow_image = convertToOptical(prev_frame, curr_frame)\n","            optical_flow_filename = os.path.join(output_folder, f\"optical_flow_{i:04d}.jpg\")\n","            cv2.imwrite(optical_flow_filename, optical_flow_image)\n","        \n","        prev_frame = curr_frame"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.499775Z","iopub.status.idle":"2024-06-14T11:09:28.500112Z","shell.execute_reply":"2024-06-14T11:09:28.499959Z","shell.execute_reply.started":"2024-06-14T11:09:28.499945Z"},"trusted":true},"outputs":[],"source":["input_folder = '/kaggle/working/frames_train'\n","output_folder = '/kaggle/working/optical_flows_train'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.501345Z","iopub.status.idle":"2024-06-14T11:09:28.501752Z","shell.execute_reply":"2024-06-14T11:09:28.501585Z","shell.execute_reply.started":"2024-06-14T11:09:28.501570Z"},"trusted":true},"outputs":[],"source":["compute_optical_flow(input_folder, output_folder)\n","print(f\"Optical flow images saved to: {output_folder}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.503022Z","iopub.status.idle":"2024-06-14T11:09:28.503313Z","shell.execute_reply":"2024-06-14T11:09:28.503179Z","shell.execute_reply.started":"2024-06-14T11:09:28.503167Z"},"trusted":true},"outputs":[],"source":["input_folder = '/kaggle/working/frames_test'\n","output_folder = '/kaggle/working/optical_flows_test'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.504412Z","iopub.status.idle":"2024-06-14T11:09:28.504818Z","shell.execute_reply":"2024-06-14T11:09:28.504647Z","shell.execute_reply.started":"2024-06-14T11:09:28.504631Z"},"trusted":true},"outputs":[],"source":["compute_optical_flow(input_folder, output_folder)\n","print(f\"Optical flow images saved to: {output_folder}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.506606Z","iopub.status.idle":"2024-06-14T11:09:28.506956Z","shell.execute_reply":"2024-06-14T11:09:28.506795Z","shell.execute_reply.started":"2024-06-14T11:09:28.506780Z"},"trusted":true},"outputs":[],"source":["class OpticalFlowDataset(Dataset):\n","    def __init__(self, optical_flow_dir, velocity_file):\n","        self.optical_flow_dir = optical_flow_dir\n","        \n","        # Get and sort the optical flow files\n","        self.optical_flow_files = sorted([f for f in os.listdir(optical_flow_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n","        \n","        # Read velocities from the text file, skipping the first line\n","        with open(velocity_file, 'r') as file:\n","            # Skip the first line\n","            file.readline()\n","            self.velocities = [float(line.strip()) for line in file]\n","        \n","        # Ensure there are the same number of files in both directories\n","        assert len(self.optical_flow_files) == len(self.velocities), \"Mismatch between optical flow files and velocity values count.\"\n","        \n","        # Define transformations (resize and normalize)\n","        self.transform = transforms.Compose([\n","            transforms.Resize((224, 224)),\n","            transforms.ToTensor(),\n","        ])\n","\n","    def __len__(self):\n","        return len(self.optical_flow_files)\n","    \n","    def __getitem__(self, idx):\n","        optical_flow_path = os.path.join(self.optical_flow_dir, self.optical_flow_files[idx])\n","        \n","        # Read the optical flow image\n","        optical_flow = cv2.imread(optical_flow_path)\n","        \n","        # Convert the NumPy array to a PIL Image\n","        optical_flow_pil = Image.fromarray(cv2.cvtColor(optical_flow, cv2.COLOR_BGR2RGB))\n","        \n","        # Apply transformations\n","        optical_flow_resized = self.transform(optical_flow_pil)\n","        \n","        # Get the velocity value and scale it between 0 and 1\n","        velocity = self.velocities[idx]\n","        velocity_scaled = (velocity - min(self.velocities)) / (max(self.velocities) - min(self.velocities))\n","        \n","        # Convert to tensors\n","        velocity_tensor = torch.tensor([velocity_scaled], dtype=torch.float32)\n","        \n","        return optical_flow_resized, velocity_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.507967Z","iopub.status.idle":"2024-06-14T11:09:28.508257Z","shell.execute_reply":"2024-06-14T11:09:28.508122Z","shell.execute_reply.started":"2024-06-14T11:09:28.508109Z"},"trusted":true},"outputs":[],"source":["train_optical_flow_dir = '/kaggle/working/optical_flows_train'\n","train_velocity_file = '/kaggle/input/q3-computer-vision/train.txt'\n","test_optical_flow_dir = '/kaggle/working/optical_flows_test'\n","test_velocity_file = '/kaggle/input/q3-computer-vision/test.txt'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.509742Z","iopub.status.idle":"2024-06-14T11:09:28.510096Z","shell.execute_reply":"2024-06-14T11:09:28.509938Z","shell.execute_reply.started":"2024-06-14T11:09:28.509923Z"},"trusted":true},"outputs":[],"source":["train_dataset = OpticalFlowDataset(train_optical_flow_dir, train_velocity_file)\n","test_dataset = OpticalFlowDataset(test_optical_flow_dir, test_velocity_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.511263Z","iopub.status.idle":"2024-06-14T11:09:28.511762Z","shell.execute_reply":"2024-06-14T11:09:28.511445Z","shell.execute_reply.started":"2024-06-14T11:09:28.511430Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.513607Z","iopub.status.idle":"2024-06-14T11:09:28.514246Z","shell.execute_reply":"2024-06-14T11:09:28.513866Z","shell.execute_reply.started":"2024-06-14T11:09:28.513844Z"},"trusted":true},"outputs":[],"source":["# Access an element from train dataset\n","train_optical_flow, train_velocity = train_dataset[100]\n","print(\"Train velocity:\", train_velocity.item())\n","print(\"Train optical flow shape:\", train_optical_flow.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.515778Z","iopub.status.idle":"2024-06-14T11:09:28.516119Z","shell.execute_reply":"2024-06-14T11:09:28.515968Z","shell.execute_reply.started":"2024-06-14T11:09:28.515953Z"},"trusted":true},"outputs":[],"source":["# Plot the optical flow image\n","plt.figure(figsize=(8, 6))\n","plt.imshow(cv2.cvtColor(train_optical_flow.numpy().transpose(1, 2, 0), cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","plt.title('Optical Flow')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.517672Z","iopub.status.idle":"2024-06-14T11:09:28.518096Z","shell.execute_reply":"2024-06-14T11:09:28.517899Z","shell.execute_reply.started":"2024-06-14T11:09:28.517883Z"},"trusted":true},"outputs":[],"source":["# Define the enhanced CNN + MLP model\n","class OpticalFlowCNN(nn.Module):\n","    def __init__(self):\n","        super(OpticalFlowCNN, self).__init__()\n","        \n","        # CNN Backbone\n","        self.cnn = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            \n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(64),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            \n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(128),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            \n","            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(256),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","            \n","            \n","        )\n","        \n","        # MLP Head\n","        self.mlp = nn.Sequential(\n","            nn.Linear(50176, 2048),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            \n","            nn.Linear(2048, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            \n","            nn.Linear(128, 1)  # Output is a single scalar (velocity)\n","        )\n","    \n","    def forward(self, x):\n","        # CNN Backbone\n","        x = self.cnn(x)\n","        \n","        # Flatten the CNN output\n","        x = x.view(x.size(0), -1)\n","        \n","        # MLP Head\n","        x = self.mlp(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.519437Z","iopub.status.idle":"2024-06-14T11:09:28.519800Z","shell.execute_reply":"2024-06-14T11:09:28.519639Z","shell.execute_reply.started":"2024-06-14T11:09:28.519624Z"},"trusted":true},"outputs":[],"source":["# Initialize model, optimizer, and criterion\n","model = OpticalFlowCNN()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.MSELoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.521793Z","iopub.status.idle":"2024-06-14T11:09:28.522147Z","shell.execute_reply":"2024-06-14T11:09:28.521992Z","shell.execute_reply.started":"2024-06-14T11:09:28.521978Z"},"trusted":true},"outputs":[],"source":["def train_and_evaluate(model, train_loader, val_loader, optimizer, criterion, num_epochs=5, device='cuda', output_csv='eval_outputs.csv'):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    \n","    # Open the CSV file in write mode initially to write the header\n","    with open(output_csv, 'w', newline='') as csvfile:\n","        fieldnames = ['epoch', 'input_id', 'prediction', 'actual']\n","        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","        writer.writeheader()\n","\n","    for epoch in range(num_epochs):\n","        # Training phase\n","        model.train()\n","        epoch_train_loss = 0.0\n","        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Train)\", unit=\"batch\") as t:\n","            for inputs, targets in t:\n","                inputs, targets = inputs.to(device), targets.to(device)\n","                optimizer.zero_grad()\n","                outputs = model(inputs)\n","                loss = criterion(outputs, targets)\n","                loss.backward()\n","                optimizer.step()\n","                epoch_train_loss += loss.item()\n","                t.set_postfix(train_loss=loss.item())\n","        \n","        avg_train_loss = epoch_train_loss / len(train_loader)\n","        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}\")\n","        \n","        # Evaluation phase\n","        model.eval()\n","        epoch_val_loss = 0.0\n","        all_eval_outputs = []\n","        with tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Val)\", unit=\"batch\") as t:\n","            for idx, (inputs, targets) in enumerate(t):\n","                with torch.no_grad():\n","                    inputs, targets = inputs.to(device), targets.to(device)\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, targets)\n","                    epoch_val_loss += loss.item()\n","                    t.set_postfix(val_loss=loss.item())\n","\n","                    # Save evaluation outputs\n","                    for i in range(len(outputs)):\n","                        all_eval_outputs.append({\n","                            'epoch': epoch + 1,\n","                            'input_id': idx * val_loader.batch_size + i,\n","                            'prediction': outputs[i].item(),\n","                            'actual': targets[i].item()\n","                        })\n","        \n","        avg_val_loss = epoch_val_loss / len(val_loader)\n","        print(f\"Epoch {epoch + 1}/{num_epochs}, Val Loss: {avg_val_loss:.4f}\")\n","\n","        # Save results to the CSV file after each epoch\n","        with open(output_csv, 'a', newline='') as csvfile:\n","            fieldnames = ['epoch', 'input_id', 'prediction', 'actual']\n","            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","            writer.writerows(all_eval_outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-14T11:09:28.523421Z","iopub.status.idle":"2024-06-14T11:09:28.523938Z","shell.execute_reply":"2024-06-14T11:09:28.523708Z","shell.execute_reply.started":"2024-06-14T11:09:28.523686Z"},"trusted":true},"outputs":[],"source":["# Train the model with evaluation\n","train_and_evaluate(model, train_loader, test_loader, optimizer, criterion, num_epochs=10)"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T11:18:35.829692Z","iopub.status.busy":"2024-06-14T11:18:35.828658Z","iopub.status.idle":"2024-06-14T11:18:35.835807Z","shell.execute_reply":"2024-06-14T11:18:35.834811Z","shell.execute_reply.started":"2024-06-14T11:18:35.829647Z"},"trusted":true},"outputs":[],"source":["# Function to read the original min and max velocities from the dataset\n","def get_velocity_scale_params(velocity_file):\n","    with open(velocity_file, 'r') as file:\n","        file.readline()  # Skip the first line\n","        velocities = [float(line.strip()) for line in file]\n","    return min(velocities), max(velocities)"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T11:18:36.836150Z","iopub.status.busy":"2024-06-14T11:18:36.835386Z","iopub.status.idle":"2024-06-14T11:18:36.842410Z","shell.execute_reply":"2024-06-14T11:18:36.841434Z","shell.execute_reply.started":"2024-06-14T11:18:36.836115Z"},"trusted":true},"outputs":[],"source":["def read_results(results_file):\n","    predictions = []\n","    actuals = []\n","    with open(results_file, 'r') as file:\n","        reader = csv.reader(file)\n","        for row in reader:\n","            if(row[0] == 'epoch'):\n","                continue\n","            epoch = int(row[0])\n","            if epoch == 1:\n","                predictions.append(float(row[2]))\n","                actuals.append(float(row[3]))\n","    return predictions, actuals"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T11:21:02.450767Z","iopub.status.busy":"2024-06-14T11:21:02.450347Z","iopub.status.idle":"2024-06-14T11:21:02.461889Z","shell.execute_reply":"2024-06-14T11:21:02.460694Z","shell.execute_reply.started":"2024-06-14T11:21:02.450727Z"},"trusted":true},"outputs":[],"source":["# Function to create video from optical flow frames and velocity results\n","def create_video_from_results(optical_flow_dir, results_file, velocity_file, output_video_path):\n","    # Read predictions and actuals from results file\n","    predictions, actuals = read_results(results_file)\n","\n","    # Get the sorted list of optical flow files\n","    optical_flow_files = sorted([f for f in os.listdir(optical_flow_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n","\n","    # Get original min and max velocities\n","    min_velocity, max_velocity = get_velocity_scale_params(velocity_file)\n","\n","    # Initialize the video writer\n","    first_frame = cv2.imread(os.path.join(optical_flow_dir, optical_flow_files[0]))\n","    height, width, layers = first_frame.shape\n","    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","    out = cv2.VideoWriter(output_video_path, fourcc, 20.0, (width, height))  # Adjust frame size and fps as needed\n","\n","    for i in tqdm(range(1, len(optical_flow_files)), desc=\"Creating video\"):\n","        optical_flow_path = os.path.join(optical_flow_dir, optical_flow_files[i])\n","        optical_flow = cv2.imread(optical_flow_path)\n","        \n","        # De-scale velocities\n","        prediction = predictions[i - 1] * (max_velocity - min_velocity) + min_velocity  # Because first frame is additional\n","        target = actuals[i - 1] * (max_velocity - min_velocity) + min_velocity\n","\n","        # Add text to frame\n","        cv2.putText(optical_flow, f'Predicted Velocity: {prediction:.2f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n","        cv2.putText(optical_flow, f'Target Velocity: {target:.2f}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n","        \n","        # Write frame to video\n","        out.write(optical_flow)\n","    \n","    out.release()"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-06-14T11:21:04.188558Z","iopub.status.busy":"2024-06-14T11:21:04.187720Z","iopub.status.idle":"2024-06-14T11:21:54.767005Z","shell.execute_reply":"2024-06-14T11:21:54.766168Z","shell.execute_reply.started":"2024-06-14T11:21:04.188504Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Creating video: 100%|██████████| 10797/10797 [00:50<00:00, 213.81it/s]\n"]}],"source":["create_video_from_results('/kaggle/working/frames_test', '/kaggle/input/test-frames-velocities/eval_outputs.csv', '/kaggle/input/q3-computer-vision/test.txt', 'output_video_origin.avi')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# google drive links\n","# https://drive.google.com/drive/folders/1Z8poyzyLqpcpfrdRJIKhL-pzEHalxnX6?usp=drive_link"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5199276,"sourceId":8674462,"sourceType":"datasetVersion"},{"datasetId":5211133,"sourceId":8690619,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
